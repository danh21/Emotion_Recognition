# Description:
    The system detects face of person, then recognizes emotion of that person and displays on the interface.

# Source:
    - train: data to train model
    - test: data to test model
    - training.ipynb: use assets from folders (train and test) to train model
    - model.h5: model after completing training
    - haarcascade_frontalface_default.xml: detect face
    - test.py: application to recognize emotion

# Instruction:
    - Use Visual Studio Code to open source code
    - Execute test.py
    - To quit app (press q key on keyboard)
    - Should take off your glasses or anything hides your face.

# Bonus:
    - Report files as .doc and .pptx are in doc folder.
    - Presentation + demo: https://youtu.be/-RavT4FCH5o